---
layout:     post
title:      "后台开发之负载均衡"
subtitle:   "关于负载均衡，你需要知道的都在这儿"
date:       2020-03-07
author:     Mcoder
header-img: img/page_header.jpg
catalog: true
tags:
    - 服务器
    - 后台开发
---

# 负载均衡 Load balancing
> 负载平衡（Load balancing）是一种计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到最优化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。 使用带有负载平衡的多个服务器组件，取代单一的组件，可以通过冗余提高可靠性。负载平衡服务通常是由专用软件和硬件来完成。 主要作用是将大量作业合理地分摊到多个操作单元上进行执行，用于解决互联网架构中的高并发和高可用的问题。

简而言之，我们不使用负载均衡的网络服务，只有一个服务器，这个服务器承担着所有的任务。如果突然访问量很大，可能会达到服务器的处理能力上限，会变得卡顿；如果服务器突然碰上了内部错误，死机后则会导致所有的用户都无法继续访问服务。

![](/post_img/201901/single_web_server.jpg)

如果说一台网页服务器`server_1.mcoder.cc 192.168.1.100`可以同时提供一百万的用户访问，那么当同时访问的用户量达到一百五十万时，这个网页服务器变会碰上性能瓶颈，可能所有用户的体验都不够好。这时我们可以选择简单的增加一台服务器`server_2.mcoder.cc 192.168.1.101`，对用户进行分流，如果两台机器均分用户，则每台只用服务七十五万的用户，在网页服务器的能力范围内，所有用户都能获得很好的体验。而如何让用户选择哪个服务器提供服务便是负载均衡服务器做的工作。负载均衡服务器对外仅是一台服务器`server.mcoder.cc 192.168.1.99`，他会选择将用户的请求转发给`server_1`或者`server_2`。

负载均衡实现了数个服务器同时提供服务，减少了单一服务器的负载，使一组服务器处理能力得到提升。而且负载均衡提高了系统的容错能力，带来了服务可用性的提升，如果其中一台服务器宕机后，还有服务器在正常工作，负载均衡服务器可以将后续的请求转发给还在工作的服务器，将死机服务器剔除。

![](/post_img/201901/lb_web_server.jpg)

目前几乎所有的云服务商都提供了负载均衡服务，如果使用诸如阿里云、腾讯云的话，直接使用他们提供的负载均衡方案即可，简单粗暴快捷。但我们可以了解下主流的负载均衡算法，对于配置服务以及后台开发技术面试都有帮助的。

# 常见负载均衡算法
负载均衡算法决定了负载均衡服务器如何将一个请求分配给后面的诸多服务器。

1. **轮询算法(Round Robin)** 和 **加权轮询（Weight Round Robin）法**: 轮转法意味着 LB 服务器会按顺序将请求分发给服务器。比如负载均衡器会将第一个请求分配给第一个服务器，然后下一个请求分配给第二个服务器，这样分配下去分配完一轮之后回到开头分配给第一个服务器。

不同的服务器可能机器配置和当前系统的负载并不相同，因此它们的抗压能力也不尽相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请求，而低配置、高负载的机器，则给其分配较低的权重，降低其系统负载。加权轮询法可以很好地处理这一问题，并将请求顺序按照权重分配到后端。

1. **随机法** 和 **加权随机（Weight Random）法**：很粗糙的方法，通过生成随机数，将连接随便转发给后端的一个服务器，当访问量加大，实际效果接近于平均分配流量到每一台后端服务器，也就是轮询的效果。
   
与加权轮询法类似，加权随机法也是根据后端服务器不同的配置和负载情况来配置不同的权重。不同的是，它是按照权重来随机选择服务器的，而不是顺序。

2. **最少连接(Least Connections)**: 最少连接方法会选择当前连接数量最少的服务器分发请求。

前面几种方法费尽心思来实现服务消费者请求次数分配的均衡，当然这么做是没错的，可以为后端的多台服务器平均分配工作量，最大程度地提高服务器的利用率但是实际情况是否真的如此？
实际情况中，请求次数的均衡真的能代表负载的均衡吗？这是一个值得思考的问题。上面的问题，再换一个角度来说就是：以后端服务器的视角来观察系统的负载，而非请求发起方来观察。最小连接数法便属于此类。最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它正是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前请求，尽可能地提高后端服务器的利用效率，将负载合理地分流到每一台机器。
   
3. **Source 原地址法**: 源地址hash，新连接先按权重分配，后续连接按source分配请求。起到会话绑定的作用，但是调度粒度太粗，使用的少，相当于是ip_hash.



# 常见框架
## NGINX
Nginx做为一个强大的Web服务器软件，具有高性能、高并发性和低内存占用的特点。此外，其也能够提供强大的反向代理功能。Nginx工作在网络的7层，可以针对http应用本身来做分流策略。支持七层HTTP、HTTPS协议的负载均衡。对四层协议的支持需要第三方插件-yaoweibin的ngx_tcp_proxy_module实现了tcp upstream。

NGINX 主要有五种负载均衡方法
```
                # 不填参数时默认是 轮询算法
least_conn;     # 最少连接方法
ip_hash;        # ip 方法
hash $request_uri consistent;   # 哈希一致性方法
least_time header;  # NGINX Plus 版本支持
random two least_time=last_byte;    # 随机算法
```


## HaProxy
Haproxy是高可用代理软件，它是一种比较流行的开源软件，基于TCP(四层)/HTTP(七层)协议的负载均衡代理解决方案，可以在Linux、FreeBSD等平台下运行，常见于跨多个服务器，比如:web、应用程序、数据库、MQ消息队列、MC数据库等等。通过多个Haproxy服务来提高服务的性能和可靠性。他支持多种负载均衡方法，如下：

```
1.balance roundrobin # 轮询，软负载均衡基本都具备这种算法
2.balance static-rr # 根据权重，建议使用
3.balance leastconn # 最少连接者先处理，建议使用
4.balance source # 根据请求源IP，建议使用
5.balance uri # 根据请求的URI
6.balance url_param，# 根据请求的URl参数'balance url_param' requires an URL parameter name
7.balance hdr(name) # 根据HTTP请求头来锁定每一次HTTP请求
8.balance rdp-cookie(name) # 根据据cookie(name)来锁定并哈希每一次TCP请求
```

# 参考文献

1. [负载均衡](https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1)